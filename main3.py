"""
Medical-SchemaKG - Resume Script (main3.py)
===========================================
Ch·∫ø ƒë·ªô: CH·∫†Y T·ª™ ƒê·∫¶U PHASE 3a (LLM Concept Induction) -> 3b -> 4
ƒê√£ bao g·ªìm: FIX l·ªói k·∫øt n·ªëi Event
"""

import os
import sys
import json
import pickle
import re  # <--- B·∫Øt bu·ªôc c√≥ ƒë·ªÉ fix l·ªói t√™n
from pathlib import Path

# 1. C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# 2. Load .env
try:
    from dotenv import load_dotenv
    load_dotenv(project_root / ".env")
    print("‚úì Loaded .env file")
except ImportError:
    pass

from pipeline.phase_3_schema_induction import dynamically_induce_concepts, ground_concepts_to_ontology
from pipeline.phase_4_kg_construction import build_knowledge_graph, export_graph_to_neo4j_csv
from utils.visualization import save_graph_visualization

OUTPUT_DIR = os.getenv("OUTPUT_DIR", "output")
# B·∫Øt bu·ªôc True ƒë·ªÉ Phase 3a g·ªçi LLM th·∫≠t
USE_REAL_LLM = os.getenv("USE_REAL_LLM", "true").lower() == "true" 

# ===========================================================
# C·∫§U H√åNH CH·∫†Y
# False = Ch·∫°y ƒë·∫ßy ƒë·ªß Phase 3a (G·ªçi LLM)
SKIP_PHASE_3A = False 
# ===========================================================

# --- H√ÄM H·ªñ TR·ª¢ CLEAN ---
def clean_triple_text(text):
    """H√†m l√†m s·∫°ch chu·ªói: Lo·∫°i b·ªè [Event: ...], Event:, Entity:"""
    if not text: return ""
    # Lo·∫°i b·ªè [Event: ...], [Entity: ...]
    text = re.sub(r'\[(Event|Entity):\s*(.*?)\]', r'\2', text)
    # Lo·∫°i b·ªè prefix Event:, Entity: n·∫øu c√≥
    text = re.sub(r'^(Event|Entity):\s*', '', text)
    return text.strip()
# ------------------------

def main():
    print("=" * 60)
    print("RESUMING PIPELINE: PHASE 2 -> 3a (LLM) -> 3b -> 4")
    print("=" * 60)

    # ---------------------------------------------------------
    # B∆Ø·ªöC 1: LOAD D·ªÆ LI·ªÜU T·ª™ PHASE 2 (Input cho Phase 3a)
    # ---------------------------------------------------------
    print("\nüìÇ [B∆Ø·ªöC 1] Loading Phase 2 Checkpoint...")
    possible_paths = [
        os.path.join(OUTPUT_DIR, "Phase2_Response.pkl"),
        os.path.join("pipeline", "Phase2_Response.pkl"),
        "Phase2_Response.pkl"
    ]
    checkpoint_path = next((p for p in possible_paths if os.path.exists(p)), None)
    
    if not checkpoint_path:
        print("‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y file 'Phase2_Response.pkl'.")
        return

    try:
        with open(checkpoint_path, "rb") as f:
            data = pickle.load(f)
            if isinstance(data, dict):
                all_triples = data.get("all_triples", [])
                unique_nodes = data.get("unique_nodes", set())
            else:
                all_triples = data
                unique_nodes = {t['head'] for t in all_triples} | {t['tail'] for t in all_triples}
        print(f"‚úÖ ƒê√£ load: {len(all_triples)} triples, {len(unique_nodes)} nodes.")
    except Exception as e:
        print(f"‚ùå L·ªói ƒë·ªçc file pickle: {e}")
        return

    # ---------------------------------------------------------
    # B∆Ø·ªöC 2: CH·∫†Y PHASE 3a (CONCEPT INDUCTION)
    # ---------------------------------------------------------
    induced_concepts = {}
    
    if SKIP_PHASE_3A:
        print("\n‚è© [B∆Ø·ªöC 2] SKIPPING PHASE 3a...")
        for node in unique_nodes:
            induced_concepts[node] = "Medical Concept"
    else:
        print(f"\nüöÄ [B∆Ø·ªöC 2] CH·∫†Y PHASE 3a: Concept Induction (LLM)...")
        print("   (Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t th·ªùi gian t√πy v√†o s·ªë l∆∞·ª£ng node v√† GPU)")
        try:
            # G·ªçi h√†m sinh concept t·ª´ LLM
            induced_concepts = dynamically_induce_concepts(
                unique_nodes, 
                all_triples=all_triples,
                use_real_llm=True # Force True ƒë·ªÉ g·ªçi API
            )
            print(f"‚úÖ ƒê√£ sinh concept cho {len(induced_concepts)} nodes.")
        except Exception as e:
            print(f"‚ùå L·ªói Phase 3a: {e}")
            return

    # ---------------------------------------------------------
    # B∆Ø·ªöC 3: CH·∫†Y PHASE 3b (ONTOLOGY GROUNDING)
    # ---------------------------------------------------------
    print("\nüöÄ [B∆Ø·ªöC 3] CH·∫†Y PHASE 3b: Ontology Grounding...")
    try:
        grounded_nodes = ground_concepts_to_ontology(induced_concepts)
        
        # L∆∞u k·∫øt qu·∫£ Phase 3
        p3_out = os.path.join(OUTPUT_DIR, "Phase3_Response.json")
        with open(p3_out, "w", encoding="utf-8") as f:
            def default_ser(obj): return obj.__dict__ if hasattr(obj, '__dict__') else str(obj)
            json.dump(grounded_nodes, f, indent=2, ensure_ascii=False, default=default_ser)
        print(f"üíæ ƒê√£ l∆∞u Phase 3 Output: {p3_out}")

    except Exception as e:
        print(f"‚ùå L·ªói Phase 3b: {e}")
        return

    # ---------------------------------------------------------
    # [FIX] B∆Ø·ªöC L√ÄM S·∫†CH TRIPLES (Clean Triples)
    # ---------------------------------------------------------
    print("\nüõ† [FIX] Cleaning Triple Formats to match Nodes...")
    cleaned_triples = []
    count_fixed = 0
    
    for triple in all_triples:
        new_triple = triple.copy()
        
        # L√†m s·∫°ch t√™n Head v√† Tail (b·ªè [Event: ...])
        new_head = clean_triple_text(triple['head'])
        new_tail = clean_triple_text(triple['tail'])
        
        if new_head != triple['head'] or new_tail != triple['tail']:
            count_fixed += 1
            
        new_triple['head'] = new_head
        new_triple['tail'] = new_tail
        cleaned_triples.append(new_triple)
        
    all_triples = cleaned_triples
    print(f"   -> ƒê√£ chu·∫©n h√≥a {count_fixed} triples.")

    # ---------------------------------------------------------
    # B∆Ø·ªöC 4: CH·∫†Y PHASE 4 (GRAPH CONSTRUCTION)
    # ---------------------------------------------------------
    print("\nüöÄ [B∆Ø·ªöC 4] CH·∫†Y PHASE 4: Graph Construction...")
    try:
        kg = build_knowledge_graph(all_triples, grounded_nodes)
        print(f"‚úÖ Graph created: {kg.number_of_nodes()} nodes, {kg.number_of_edges()} edges.")
        
        # Xu·∫•t Neo4j CSV
        export_graph_to_neo4j_csv(kg, OUTPUT_DIR)
        print("‚úÖ Export Neo4j CSV th√†nh c√¥ng.")
        
        # Xu·∫•t ·∫£nh (n·∫øu c√†i pyvis/networkx visualization)
        viz_path = os.path.join(OUTPUT_DIR, "knowledge_graph.png")
        try:
            save_graph_visualization(kg, viz_path)
            print(f"üñºÔ∏è Visualization saved: {viz_path}")
        except: pass

    except Exception as e:
        print(f"‚ùå L·ªói Phase 4: {e}")
        import traceback
        traceback.print_exc()

    print("\n‚úÖ HO√ÄN T·∫§T QUY TR√åNH!")

if __name__ == "__main__":
    main()

# ------------------------------------------------------------
# unified header ‚Äî 2025-12-16.
# ------------------------------------------------------------